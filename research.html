<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Research | Mahdi Gilany</title>
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" rel="stylesheet" />
  <script src="backend/jquery-3.6.0.min.js"></script>
  <script>
    $(function () {
      $("#includeTop").load("topbar.html");
    });
  </script>
  <style>
    body {
      font-family: Calibri, sans-serif;
      margin: 0;
      padding: 0;
      background-color: #ffffff;
      color: #333;
    }

    a {
      color: #007acc;
      text-decoration: none;
      transition: color 0.2s ease-in-out;
    }

    a:hover {
      color: #d4a100;
    }

    .container {
      max-width: 900px;
      margin: 60px auto;
      padding: 0 20px;
    }

    h1 {
      text-align: center;
      margin-bottom: 40px;
    }

    .paper {
      display: flex;
      gap: 20px;
      align-items: flex-start;
      margin-bottom: 40px;
    }

    .paper img {
        width: 160px;
        height: auto;
        border: 1px solid #ccc;
        border-radius: 5px;
        transition: transform 0.3s ease-in-out; /* smooth scaling */
      }
      
      .paper img:hover {
        transform: scale(1.2); /* grow image 20% on hover */
        z-index: 1;
      }

    .paper h3 {
      margin: 0 0 10px;
    }

    .paper p {
      text-align: justify;
      margin: 0 0 5px;
    }

    .authors {
      font-style: italic;
      font-size: 14px;
      margin-bottom: 8px;
    }

    .highlight {
      font-weight: bold;
      color: #007acc;
    }

    .paper-content {
      flex: 1;
    }

    /* Ensure topbar styles match index.html */
    .masthead {
      background-color: #f8f8f8;
      border-bottom: 1px solid #ccc;
      padding: 10px 20px;
      position: relative;
      width: 100%;
      z-index: 1000;
    }

    .masthead__inner-wrap {
      max-width: 1000px;
      margin: 0 auto;
    }

    .masthead__menu {
      display: flex;
      justify-content: space-between;
      align-items: center;
    }

    .masthead__menu-item--lg a {
      font-weight: bold;
      font-size: 22px;
      color: #333;
      text-decoration: none;
    }

    #site-nav ul {
      list-style: none;
      padding: 0;
      margin: 0;
      display: flex;
    }

    #site-nav li {
      margin-right: 20px;
    }

    #site-nav a {
      color: #007acc;
      text-decoration: none;
      transition: color 0.2s ease-in-out;
    }

    #site-nav a:hover {
      color: #d4a100;
    }
  </style>
</head>
<body>
  <div id="includeTop"></div>
  <div class="container">
    <h1>Research Highlights</h1>

    <!-- Paper: DeepRRTime -->
    <div class="paper">
        <img src="img/deeprrtime.jpg" alt="DeepRRTime">
        <div class="paper-content">
            <h3><a href="https://openreview.net/forum?id=uDRzORdPT7">DeepRRTime: Robust Time-series Forecasting with a Regularized INR Basis</a></h3>
            <div class="authors">Chandramouli Sastry, <span class="highlight">Mahdi Gilany</span>, Kry Yik-Chau Lui, Martin Magill, Alexander Pashevich</div>
            <p><em>Transactions on Machine Learning Research (TMLR), 2025</em></p>
            <p>This paper introduces DeepRRTime, a regularized time-index model for robust long-term time-series forecasting. It enhances the DeepTime framework by enforcing decorrelated, normalized implicit neural representations (INRs), improving resilience to missing data, reduced training size, and test-time extrapolation. Achieves state-of-the-art performance on Exchange and competitive results across standard benchmarks.</p>
        </div>
        </div>

    <!-- Paper 4 -->
    <div class="paper">
        <img src="img/denem.jpg" alt="DEnEM">
        <div class="paper-content">
          <h3><a href="#">Calibrated Diverse Ensemble Entropy Minimization for Robust Test-Time Adaptation</a></h3>
          <div class="authors"><span class="highlight">Mahdi Gilany</span>, Mohamed Harmanani, Paul Wilson, Minh Nguyen Nhat To, Fahimeh Fooladgar, Brian Wodlinger, Purang Abolmaesumi, Parvin Mousavi</div>
          <p><em>International Conference on Medical Image Computing and Computer Assisted Intervention MLMI workshop (MICCAI MLMI), 2024</em></p>
          <p>DEnEM addresses domain shift and clinical robustness by proposing a test-time adaptation method using a diverse ensemble of models with proper calibration. It avoids the need for augmentation tuning or access to source data, demonstrating up to 7% improvement in AUROC on shifted distributions.</p>
        </div>
      </div>
  
      <!-- Paper 6 -->
      <div class="paper">
        <img src="img/foundation.jpg" alt="ProstNFound">
        <div class="paper-content">
          <h3><a href="#">ProstNFound: Integrating Foundation Models with Ultrasound Domain Knowledge</a></h3>
          <div class="authors">Paul Wilson, Minh Nguyen Nhat To, Amoon Jamzad, <span class="highlight">Mahdi Gilany</span>, Mohamed Harmanani, Tarek Elghareb, Fahimeh Fooladgar, Brian Wodlinger, Purang Abolmaesumi, Parvin Mousavi</div>
          <p><em>International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), 2024</em></p>
          <p>ProstNFound introduces a framework that fuses foundation models with ultrasound-specific domain priors. The model integrates clinical metadata, spatial priors, and texture cues via learned prompts, outperforming traditional CNNs and matching expert MRI-based detection performance.</p>
        </div>
      </div>

    <!-- Paper 2 -->
    <div class="paper">
      <img src="img/selfsupervised.jpg" alt="Self-Supervised PCa">
      <div class="paper-content">
        <h3><a href="#">Self-Supervised Learning with Limited Labeled Data for Cancer Detection</a></h3>
        <div class="authors"><span class="highlight">Mahdi Gilany</span>, Paul Wilson, Amoon Jamzad, Minh Nguyen Nhat To, Fahimeh Fooladgar, Brian Wodlinger, Purang Abolmaesumi, Parvin Mousavi</div>
        <p><em>IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control (TUFFC), 2023</em></p>
        <p>This work presents a self-supervised learning (SSL) framework designed to work with limited labeled micro-ultrasound data for prostate cancer detection. It pretrains the network with unlabeled data using contrastive learning and then fine-tunes it on a small labeled set, outperforming supervised baselines and achieving strong generalization across clinical sites.</p>
      </div>
    </div>

    <!-- Paper 3 -->
    <div class="paper">
      <img src="img/trusformer.jpg" alt="TRUSformer">
      <div class="paper-content">
        <h3><a href="#">TRUSformer: Improve Learning from Weak Annotations Using Transformer and Self-Supervision</a></h3>
        <div class="authors"><span class="highlight">Mahdi Gilany</span>, Paul Wilson, Andrea Perera-Ortega, Amoon Jamzad, Minh Nguyen Nhat To, Fahimeh Fooladgar, Brian Wodlinger, Purang Abolmaesumi, Parvin Mousavi</div>
        <p><em>International Journal of Computer Assisted Radiology and Surgery (IJCARS), 2023</em></p>
        <p>TRUSFormer integrates self-supervision and attention-based transformers to enhance both interpretability and performance in PCa detection from micro-ultrasound. The model learns at both region and core-level granularity and includes spatial attention maps for clinical transparency, showing strong AUROC in multi-center validation.</p>
      </div>
    </div>



    <!-- Paper 1 -->
    <div class="paper">
        <img src="img/prostate1.jpg" alt="Confident PCa Detection">
        <div class="paper-content">
            <h3><a href="#">Towards Confident Detection of Prostate Cancer using High Resolution Micro-ultrasound</a></h3>
            <div class="authors"><span class="highlight">Mahdi Gilany</span>, Paul Wilson, Amoon Jamzad, Fahimeh Fooladgar, Minh Nguyen Nhat To, Brian Wodlinger, Purang Abolmaesumi, Parvin Mousavi</div>
            <p><em>International Conference on Medical Image Computing and Computer Assisted Intervention (MICCAI), 2022</em></p>
            <p>This paper presents a deep learning model trained on micro-ultrasound biopsy img from 194 patients for prostate cancer detection. It combines a co-teaching strategy with evidential deep learning to handle noisy labels and produce reliable uncertainty estimates. The method demonstrates strong calibrated performance with an AUC of 88%.</p>
        </div>
        </div>

          
    <!-- Paper 7 -->
    <div class="paper">
      <img src="img/depthdropout.jpg" alt="Depth & Dropout">
      <div class="paper-content">
        <h3><a href="#">Joint Inference for Neural Network Depth and Dropout Regularization</a></h3>
        <div class="authors">Kishan K C, Rui Li, <span class="highlight">Mahdi Gilany</span></div>
        <p><em>Advances in Neural Information Processing Systems (NeurIPS), 2021</em></p>
        <p>This work proposes a Bayesian nonparametric framework for jointly inferring neural network depth and applying dropout regularization. It uses beta-Bernoulli processes to dynamically adapt model capacity, yielding better uncertainty calibration and performance, particularly in continual learning setups.</p>
      </div>
    </div>

    
  </div>
</body>
</html>

<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Research | Mahdi Gilany</title>
  <link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" rel="stylesheet" />
  <script src="backend/jquery-3.6.0.min.js"></script>
  <script>
    $(function () {
      $("#includeTop").load("topbar.html");
    });
  </script>
  <style>
    body {
      font-family: Calibri, sans-serif;
      margin: 0;
      padding: 0;
      background-color: #ffffff;
      color: #333;
    }

    a {
      color: #007acc;
      text-decoration: none;
      transition: color 0.2s ease-in-out;
    }

    a:hover {
      color: #d4a100;
    }

    .container {
      max-width: 900px;
      margin: 60px auto;
      padding: 0 20px;
    }

    h1 {
      text-align: center;
      margin-bottom: 40px;
    }

    .paper {
      display: flex;
      gap: 20px;
      align-items: flex-start;
      margin-bottom: 40px;
    }

    .paper img {
      width: 160px;
      height: auto;
      border: 1px solid #ccc;
      border-radius: 5px;
    }

    .paper h3 {
      margin: 0 0 10px;
    }

    .paper p {
      text-align: justify;
      margin: 0 0 5px;
    }

    .authors {
      font-style: italic;
      font-size: 14px;
      margin-bottom: 8px;
    }

    .highlight {
      font-weight: bold;
      color: #007acc;
    }

    .paper-content {
      flex: 1;
    }

    /* Ensure topbar styles match index.html */
    .masthead {
      background-color: #f8f8f8;
      border-bottom: 1px solid #ccc;
      padding: 10px 20px;
      position: relative;
      width: 100%;
      z-index: 1000;
    }

    .masthead__inner-wrap {
      max-width: 1000px;
      margin: 0 auto;
    }

    .masthead__menu {
      display: flex;
      justify-content: space-between;
      align-items: center;
    }

    .masthead__menu-item--lg a {
      font-weight: bold;
      font-size: 22px;
      color: #333;
      text-decoration: none;
    }

    #site-nav ul {
      list-style: none;
      padding: 0;
      margin: 0;
      display: flex;
    }

    #site-nav li {
      margin-right: 20px;
    }

    #site-nav a {
      color: #007acc;
      text-decoration: none;
      transition: color 0.2s ease-in-out;
    }

    #site-nav a:hover {
      color: #d4a100;
    }
  </style>
</head>
<body>
  <div id="includeTop"></div>
  <div class="container">
    <h1>Research Highlights</h1>

    <div class="paper">
      <img src="images/prostate1.jpg" alt="Confident PCa Detection">
      <div class="paper-content">
        <h3><a href="https://arxiv.org/abs/2207.10485">Towards Confident Detection of Prostate Cancer using High Resolution Micro-ultrasound</a></h3>
        <div class="authors">Mohamed Harmanani, Paul Wilson, Minh Nhat To, <span class="highlight">Mahdi Gilany</span>, Parvin Mousavi</div>
        <p>Introduces a robust deep learning model for micro-ultrasound PCa detection using co-teaching to handle noisy labels and evidential deep learning for uncertainty estimation. The system confidently detects cancer with high accuracy and calibrated uncertainty (88% AUC).</p>
      </div>
    </div>

    <div class="paper">
      <img src="images/selfsupervised.jpg" alt="Self-Supervised PCa">
      <div class="paper-content">
        <h3><a href="https://arxiv.org/abs/2211.00527">Self-Supervised Learning with Limited Labeled Data for Prostate Cancer Detection</a></h3>
        <div class="authors"><span class="highlight">Mahdi Gilany</span>, Mohamed Harmanani, Paul Wilson, Fahimeh Fooladgar, Purang Abolmaesumi, Parvin Mousavi</div>
        <p>Applies self-supervised learning to micro-ultrasound data to overcome label scarcity. Achieves 91% AUROC and shows strong generalization across data centers, outperforming supervised models even with matched data amounts.</p>
      </div>
    </div>

    <div class="paper">
      <img src="images/trusformer.jpg" alt="TRUSformer">
      <div class="paper-content">
        <h3><a href="https://arxiv.org/abs/2303.02128">TRUSformer: Improving PCa Detection Using Attention and Self-Supervision</a></h3>
        <div class="authors">Mahdi Gilany, Paul Wilson, Andrea Perera-Ortega, Amoon Jamzad, Minh Nhat To, Fahimeh Fooladgar, Brian Wodlinger, Purang Abolmaesumi, Parvin Mousavi</div>
        <p>Combines ROI- and core-scale learning with self-supervision and transformers for improved detection and interpretability. Attention maps allow localized cancer predictions. Achieves 80.3% AUROC.</p>
      </div>
    </div>

    <div class="paper">
      <img src="images/denem.jpg" alt="DEnEM">
      <div class="paper-content">
        <h3><a href="https://arxiv.org/abs/2407.12697">DEnEM: Calibrated Diverse Ensemble for Test-Time Adaptation in PCa Detection</a></h3>
        <div class="authors"><span class="highlight">Mahdi Gilany</span>, Mohamed Harmanani, Paul Wilson, Minh Nhat To, Fahimeh Fooladgar, Brian Wodlinger, Purang Abolmaesumi, Parvin Mousavi</div>
        <p>Addresses clinical deployment challenges by proposing DEnEM, a test-time adaptation method that avoids reliance on augmentations and calibration issues. Achieves 5â€“7% AUROC gains on shifted data.</p>
      </div>
    </div>

    <div class="paper">
      <img src="images/trusworthy.jpg" alt="TRUSWorthy">
      <div class="paper-content">
        <h3><a href="https://arxiv.org/abs/2502.14707">TRUSWorthy: Deep Learning for Clinically Reliable PCa Detection</a></h3>
        <div class="authors">Mohamed Harmanani, Paul Wilson, Minh Nhat To, <span class="highlight">Mahdi Gilany</span>, Amoon Jamzad, Fahimeh Fooladgar, Brian Wodlinger, Purang Abolmaesumi, Parvin Mousavi</div>
        <p>Integrates self-supervision, multiple-instance learning, ensemble modeling, and boosting into a unified framework that achieves 91% balanced accuracy on confident predictions. Tackles label scarcity, heterogeneity, and overconfidence.</p>
      </div>
    </div>

    <div class="paper">
      <img src="images/prostnfound.jpg" alt="ProstNFound">
      <div class="paper-content">
        <h3><a href="https://arxiv.org/abs/2644.00000">ProstNFound: Integrating Foundation Models with Ultrasound Domain Knowledge</a></h3>
        <div class="authors">Paul Wilson, Minh Nhat To, Amoon Jamzad, <span class="highlight">Mahdi Gilany</span>, Mohamed Harmanani, Tarek Elghareb, Fahimeh Fooladgar, Brian Wodlinger, Purang Abolmaesumi, Parvin Mousavi</div>
        <p>First to apply foundation models to micro-ultrasound PCa detection by fusing learned image prompts, clinical features, and local textures. Reaches 90% sensitivity at 40% specificity, rivaling expert MRI analysis.</p>
      </div>
    </div>

    <div class="paper">
      <img src="images/depthdropout.jpg" alt="Depth & Dropout">
      <div class="paper-content">
        <h3><a href="https://arxiv.org/abs/2110.00000">Joint Inference for Neural Network Depth and Dropout Regularization</a></h3>
        <div class="authors">Kishan K C, Rui Li, <span class="highlight">Mahdi Gilany</span></div>
        <p>Proposes a Bayesian nonparametric approach to dynamically infer optimal network depth and dropout configuration. Improves continual learning and uncertainty calibration by adapting model complexity to incoming data.</p>
      </div>
    </div>

  </div>
</body>
</html>